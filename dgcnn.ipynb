{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OM4ko4PpgTP9",
        "outputId": "8beb5ca1-59cd-432e-bbc0-4516b49a2414"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torcheeg import transforms\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torcheeg.datasets import SEEDDataset\n",
        "from torcheeg.models import DGCNN\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader, Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO: dataset接受收集的数据\n",
        "dataset = SEEDDataset(io_path='/Users/hanlin/Desktop/vr_locomotion/seed',  # 设置为之前保存数据的路径\n",
        "                      offline_transform=transforms.BandDifferentialEntropy(band_dict={\n",
        "                          \"delta\": [1, 4],\n",
        "                          \"theta\": [4, 8],\n",
        "                          \"alpha\": [8, 14],\n",
        "                          \"beta\": [14, 31],\n",
        "                          \"gamma\": [31, 49]\n",
        "                      }),\n",
        "                      online_transform=transforms.Compose([\n",
        "                          transforms.ToTensor()\n",
        "                      ]),\n",
        "                      label_transform=transforms.Compose([\n",
        "                          transforms.Select('emotion'),\n",
        "                          transforms.Lambda(lambda x: x + 1)\n",
        "                      ]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 划分数据集为训练集、验证集和测试集\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "train_size = int(train_ratio * len(dataset))\n",
        "val_size = int(val_ratio * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# TODO: 设置超参数\n",
        "batch_size = 32\n",
        "num_epochs = 100\n",
        "# l1_reg = 0\n",
        "# l2_reg = 0\n",
        "learning_rate = 0.0001\n",
        "\n",
        "# 创建数据加载器\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# TODO: 修改模型参数\n",
        "model = DGCNN(in_channels=5, num_electrodes=62, hid_channels=32, num_layers=2, num_classes=3)\n",
        "\n",
        "# 定义损失函数和优化器\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "# 训练模型\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for batch_data, batch_labels in train_loader:\n",
        "        # 训练代码\n",
        "        # 将数据传递给模型\n",
        "        outputs = model(batch_data)\n",
        "        \n",
        "        # 计算交叉熵损失\n",
        "        ce_loss = criterion(outputs, batch_labels)\n",
        "        \n",
        "        # # 计算L1正则项\n",
        "        # l1_reg_loss = 0\n",
        "        # for param in model.parameters():\n",
        "        #     l1_reg_loss += torch.sum(torch.abs(param))\n",
        "        # # 计算总损失\n",
        "        # loss = ce_loss + l1_reg * l1_reg_loss\n",
        "\n",
        "        # 计算L2正则项\n",
        "        l2_reg_loss = 0\n",
        "        for param in model.parameters():\n",
        "            l2_reg_loss += torch.sum(torch.pow(param, 2))\n",
        "        \n",
        "        # 计算总损失\n",
        "        loss = ce_loss + l2_reg * l2_reg_loss\n",
        "        \n",
        "        # 反向传播和优化\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    # 在验证集上评估模型\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_data, batch_labels in val_loader:\n",
        "            outputs = model(batch_data)\n",
        "            loss = criterion(outputs, batch_labels)\n",
        "            val_loss += loss.item()\n",
        "    \n",
        "    # 计算平均训练损失和验证损失\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    val_loss = val_loss / len(val_loader)\n",
        "    \n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    \n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "# 绘制训练损失和验证损失的图表\n",
        "import matplotlib.pyplot as plt\n",
        "epochs = range(1, num_epochs + 1)\n",
        "plt.plot(epochs, train_losses, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_losses, 'r', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss, l2_reg: ' + str(l2_reg))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 在测试集上评估模型\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_data, batch_labels in test_loader:\n",
        "        outputs = model(batch_data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += batch_labels.size(0)\n",
        "        correct += (predicted == batch_labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
